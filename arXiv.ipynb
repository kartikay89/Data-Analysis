{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# arxiv_data = []\n",
    "\n",
    "# for line in open(\"/Volumes/Kartikay/Data/arxiv-metadata-oai-snapshot.json\"):\n",
    "#     data = json.loads(line)\n",
    "#     arxiv_data.append(data)\n",
    "# #     print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the 0th element of the file.\n",
    "# arxiv_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_DF =[]\n",
    "# submitters_DF = []\n",
    "# authors_DF = []\n",
    "# title_DF = []\n",
    "# journalRef_DF = []\n",
    "# categories_DF = []\n",
    "# license_DF = []\n",
    "# abstract_DF = []\n",
    "\n",
    "# for ids in arxiv_data:\n",
    "#     id_DF.append(ids['id'])\n",
    "# for subs in arxiv_data:\n",
    "#     submitters_DF.append(subs['submitter'])\n",
    "# for author in arxiv_data:\n",
    "#     authors_DF.append(author['authors'])\n",
    "# for titles in arxiv_data:\n",
    "#     title_DF.append(titles['title'])\n",
    "# for journals in arxiv_data:\n",
    "#     journalRef_DF.append(journals['journal-ref'])\n",
    "# for categories in arxiv_data:\n",
    "#     categories_DF.append(categories['categories'])\n",
    "# for license in arxiv_data:\n",
    "#     license_DF.append(license['license'])\n",
    "# for abstracts in arxiv_data:\n",
    "#     abstract_DF.append(abstracts['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code works well with creating SQLITE database. But we are not using it here.\n",
    "\n",
    "# conn = sqlite3.connect('arxiv.db')\n",
    "# c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.execute('''CREATE TABLE arxiv\n",
    "#              (Id text, Submitter text)''')\n",
    "\n",
    "# # Insert a row of data\n",
    "# for ids in id_DF:\n",
    "#     for subs in submitters:\n",
    "#         c.execute(\"INSERT INTO arxiv VALUES (?, ?)\" , (ids, subs,))\n",
    "# #         c.execute(\"INSERT INTO arxiv VALUES (?)\" , (subs,))\n",
    "\n",
    "# # Save (commit) the changes\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating dataframes from the JSON file.\n",
    "# arxiv_ID_df = pd.DataFrame(id_DF, columns=['Id'])\n",
    "# arxiv_Subs_df = pd.DataFrame(submitters_DF, columns=['Submitters'])\n",
    "# arxiv_authors_df = pd.DataFrame(authors_DF, columns=['Authors'])\n",
    "# arxiv_title_df = pd.DataFrame(title_DF, columns=['Titles'])\n",
    "# arxiv_journalRef_df = pd.DataFrame(journalRef_DF, columns=['Journal_Reference'])\n",
    "# arxiv_categories_df = pd.DataFrame(categories_DF, columns=['Categories'])\n",
    "# arxiv_license_df = pd.DataFrame(license_DF, columns=['License'])\n",
    "# arxiv_abstract_df = pd.DataFrame(abstract_DF, columns=['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = [arxiv_ID_df, arxiv_Subs_df, arxiv_authors_df, arxiv_title_df, arxiv_journalRef_df, arxiv_categories_df, arxiv_license_df, arxiv_abstract_df]\n",
    "\n",
    "# FinalDF = pd.concat(frames, axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinalDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unique Authors\n",
    "# list(set(list(FinalDF['Submitters'])))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The number of unique authors are: {} out of {}'.format(len(set(list(FinalDF['Submitters']))), len(list(FinalDF['Submitters'])) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let us count the number of contributions from these authors.\n",
    "# AuthorCount = []\n",
    "# AuthorCount_dict = {}\n",
    "\n",
    "# submittersList = list(FinalDF['Submitters'])\n",
    "\n",
    "# AuthorCount.append(Counter(submittersList))\n",
    "\n",
    "# for authors in AuthorCount:\n",
    "#     for key, value in authors.items():\n",
    "#         AuthorCount_dict[key]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(AuthorCount_dict.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: cd: open: No such file or directory\n",
      " 1796911 /Volumes/Kartikay/Data/arxiv-metadata-oai-snapshot.json\n",
      " 1796911 total\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of lines in the original file using bash to split it into smaller equal pieces.\n",
    "!wc -l cd /Volumes/Kartikay/Data/arxiv-metadata-oai-snapshot.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*/Volumes/Kartikay/Data/split_dataFiles/aa.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ab.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ac.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ad.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ae.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/af.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ag.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ah.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ai.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/aj.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ak.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/al.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/am.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/an.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ao.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ap.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/aq.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/ar.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/as.json\r\n",
      "*/Volumes/Kartikay/Data/split_dataFiles/at.json\r\n"
     ]
    }
   ],
   "source": [
    "# The project consists of a bash script that splits the data into chunks - refer: github: scripts.bash\n",
    "\n",
    "# The script is developed to handle big data(~3gigs) in a single computer - Time for processing data cut down from 1 hour to 1 min. \n",
    "\n",
    "!for i in /Volumes/Kartikay/Data/split_dataFiles/*; do echo *${i}; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lists contain all information from different json files.\n",
    "\n",
    "data_one = []\n",
    "    \n",
    "for line in open(\"/Volumes/Kartikay/Data/split_dataFiles/aa.json\"):\n",
    "    data = json.loads(line)\n",
    "    data_one.append(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.0001',\n",
       " 'submitter': 'Pavel Nadolsky',\n",
       " 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
       " 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
       " 'comments': '37 pages, 15 figures; published version',\n",
       " 'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
       " 'doi': '10.1103/PhysRevD.76.013009',\n",
       " 'report-no': 'ANL-HEP-PR-07-12',\n",
       " 'categories': 'hep-ph',\n",
       " 'license': None,\n",
       " 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
       " 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'},\n",
       "  {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}],\n",
       " 'update_date': '2008-11-26',\n",
       " 'authors_parsed': [['Bal√°zs', 'C.', ''],\n",
       "  ['Berger', 'E. L.', ''],\n",
       "  ['Nadolsky', 'P. M.', ''],\n",
       "  ['Yuan', 'C. -P.', '']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_one[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an object for extracting data from all lists of json files and creating dataframe.\n",
    "class journals:\n",
    "      \n",
    "    def __init__(self, ids, title, journal_Reference, license, abstract, idsTwo, titleTwo, journal_ReferenceTwo, licenseTwo, abstractTwo):\n",
    "\n",
    "        self.ids = ids\n",
    "        self.title = title\n",
    "        self.journal_Reference = journal_Reference\n",
    "        self.license = license\n",
    "        self.abstract = abstract\n",
    "        \n",
    "\n",
    "class author(journals):\n",
    "    \n",
    "    def __init__(self, submitter, authors):\n",
    "\n",
    "        self.submitter = submitter\n",
    "        self.authors = authors\n",
    "    \n",
    "    def fileNumberGenerator():\n",
    "        \n",
    "        # Creating dataframes from the JSON file.\n",
    "        arxiv_ID = pd.DataFrame(journals.ids, columns=['Ids'])\n",
    "        arxiv_title = pd.DataFrame(journals.title, columns=['Titles'])\n",
    "        arxiv_subs = pd.DataFrame(journals.submitter, columns=['Submitters'])\n",
    "        arxiv_authorz = pd.DataFrame(journals.authors, columns=['Authors'])\n",
    "        arxiv_journalRefs = pd.DataFrame(journals.journal_Reference, columns=['Journal_Reference'])\n",
    "        arxiv_license = pd.DataFrame(journals.license, columns=['License'])\n",
    "        arxiv_abstract = pd.DataFrame(journals.abstract, columns=['Abstract'])\n",
    "        \n",
    "        frames = [arxiv_ID, arxiv_title,  arxiv_subs, arxiv_authorz, arxiv_journalRefs, arxiv_license, arxiv_abstract]\n",
    "\n",
    "        FinalDF = pd.concat(frames, axis=1, sort=True)\n",
    "        \n",
    "        return FinalDF\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lists contain data from first json file:\n",
    "\n",
    "\n",
    "def populateData(data):\n",
    "    \n",
    "    dataId_list = []\n",
    "    dataTitle_list = []\n",
    "    dataSub_list = []\n",
    "    dataAuthors_list = []\n",
    "    dataJournalsRef_list = []\n",
    "    dataLicense_list = []\n",
    "    dataAbstract_list = []\n",
    "\n",
    "    \n",
    "\n",
    "    for ids in data:\n",
    "        dataId_list.append(ids['id'])\n",
    "        journals.ids = dataId_list\n",
    "\n",
    "    for titles in data:\n",
    "        dataTitle_list.append(titles['title'])\n",
    "        journals.title = dataTitle_list\n",
    "\n",
    "    for subs in data:\n",
    "        dataSub_list.append(subs['submitter'])\n",
    "        journals.submitter = dataSub_list\n",
    "\n",
    "    for authorz in data:\n",
    "        dataAuthors_list.append(authorz['authors'])\n",
    "        journals.authors = dataAuthors_list\n",
    "\n",
    "    for journalRefs in data:\n",
    "        dataJournalsRef_list.append(journalRefs['journal-ref'])\n",
    "        journals.journal_Reference = dataJournalsRef_list\n",
    "\n",
    "    for licenses in data:\n",
    "        dataLicense_list.append(licenses['license'])\n",
    "        journals.license = dataLicense_list\n",
    "\n",
    "    for abstracts in data:\n",
    "        dataAbstract_list.append(abstracts['abstract'])\n",
    "        journals.abstract = dataAbstract_list\n",
    "\n",
    "populateData(data_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Titles</th>\n",
       "      <th>Submitters</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Journal_Reference</th>\n",
       "      <th>License</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>None</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>Alberto Torchinsky</td>\n",
       "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
       "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
       "      <td>None</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ids                                             Titles  \\\n",
       "0  0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2  0704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3  0704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4  0704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "           Submitters                                            Authors  \\\n",
       "0      Pavel Nadolsky  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1        Louis Theran                    Ileana Streinu and Louis Theran   \n",
       "2         Hongjun Pan                                        Hongjun Pan   \n",
       "3        David Callan                                       David Callan   \n",
       "4  Alberto Torchinsky           Wael Abu-Shammala and Alberto Torchinsky   \n",
       "\n",
       "                           Journal_Reference  \\\n",
       "0                   Phys.Rev.D76:013009,2007   \n",
       "1                                       None   \n",
       "2                                       None   \n",
       "3                                       None   \n",
       "4  Illinois J. Math. 52 (2008) no.2, 681-689   \n",
       "\n",
       "                                             License  \\\n",
       "0                                               None   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                            Abstract  \n",
       "0    A fully differential calculation in perturba...  \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...  \n",
       "2    The evolution of Earth-Moon system is descri...  \n",
       "3    We show that a determinant of Stirling cycle...  \n",
       "4    In this paper we show how to compute the $\\L...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FrameOne = author.fileNumberGenerator()\n",
    "FrameOne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the second data file:\n",
    "data_two = []\n",
    "    \n",
    "for line in open(\"/Volumes/Kartikay/Data/split_dataFiles/ab.json\"):\n",
    "    dataTwo = json.loads(line)\n",
    "    data_two.append(dataTwo)\n",
    "\n",
    "populateData(data_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Titles</th>\n",
       "      <th>Submitters</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Journal_Reference</th>\n",
       "      <th>License</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0810.4421</td>\n",
       "      <td>Dark Energy and Dark Matter in General Relativ...</td>\n",
       "      <td>Pankaj Jain</td>\n",
       "      <td>Pavan Kumar Aluri, Pankaj Jain and Naveen K. S...</td>\n",
       "      <td>Mod.Phys.Lett.A24:1583-1595,2009</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We consider a generalization of Einstein's g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0810.4422</td>\n",
       "      <td>Wind speed classification using Dirichlet mixt...</td>\n",
       "      <td>Rudy Calif</td>\n",
       "      <td>Rudy Calif (GRER), Richard Emilion (MAPMO), Te...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Wind energy production is very sensitive to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0810.4423</td>\n",
       "      <td>Efficient Algorithmic Techniques for Several M...</td>\n",
       "      <td>Mugurel Ionut Andreica</td>\n",
       "      <td>Mugurel Ionut Andreica</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>In this paper I present several novel, effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0810.4424</td>\n",
       "      <td>Bond Orientational Order Parameters in the Cry...</td>\n",
       "      <td>Martial Mazars Dr.</td>\n",
       "      <td>Martial Mazars (Laboratoire de Physique Theori...</td>\n",
       "      <td>EPL, 84, 55002 (2008)</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We present a study of the structural propert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0810.4425</td>\n",
       "      <td>Evidence for Two-Dimensional Spin-Glass Orderi...</td>\n",
       "      <td>Tohru Okamoto</td>\n",
       "      <td>Toshimitsu Mochizuki, Ryuichi Masutomi, Tohru ...</td>\n",
       "      <td>Phys. Rev. Lett. 101, 267204 (2008)</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Magnetotransport measurements have been perf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ids                                             Titles  \\\n",
       "0  0810.4421  Dark Energy and Dark Matter in General Relativ...   \n",
       "1  0810.4422  Wind speed classification using Dirichlet mixt...   \n",
       "2  0810.4423  Efficient Algorithmic Techniques for Several M...   \n",
       "3  0810.4424  Bond Orientational Order Parameters in the Cry...   \n",
       "4  0810.4425  Evidence for Two-Dimensional Spin-Glass Orderi...   \n",
       "\n",
       "               Submitters                                            Authors  \\\n",
       "0             Pankaj Jain  Pavan Kumar Aluri, Pankaj Jain and Naveen K. S...   \n",
       "1              Rudy Calif  Rudy Calif (GRER), Richard Emilion (MAPMO), Te...   \n",
       "2  Mugurel Ionut Andreica                             Mugurel Ionut Andreica   \n",
       "3      Martial Mazars Dr.  Martial Mazars (Laboratoire de Physique Theori...   \n",
       "4           Tohru Okamoto  Toshimitsu Mochizuki, Ryuichi Masutomi, Tohru ...   \n",
       "\n",
       "                     Journal_Reference  \\\n",
       "0     Mod.Phys.Lett.A24:1583-1595,2009   \n",
       "1                                 None   \n",
       "2                                 None   \n",
       "3                EPL, 84, 55002 (2008)   \n",
       "4  Phys. Rev. Lett. 101, 267204 (2008)   \n",
       "\n",
       "                                             License  \\\n",
       "0  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "3  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "4  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                            Abstract  \n",
       "0    We consider a generalization of Einstein's g...  \n",
       "1    Wind energy production is very sensitive to ...  \n",
       "2    In this paper I present several novel, effic...  \n",
       "3    We present a study of the structural propert...  \n",
       "4    Magnetotransport measurements have been perf...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FrameTwo = author.fileNumberGenerator()\n",
    "FrameTwo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa.json', 'ab.json', 'ac.json', 'ad.json', 'ae.json', 'af.json', 'ag.json', 'ah.json', 'ai.json', 'aj.json', 'ak.json', 'al.json', 'am.json', 'an.json', 'ao.json', 'ap.json', 'aq.json', 'ar.json', 'as.json', 'at.json']\n",
      "<class 'list'>\n",
      "0 aa.json\n",
      "1 ab.json\n",
      "2 ac.json\n",
      "3 ad.json\n",
      "4 ae.json\n",
      "5 af.json\n",
      "6 ag.json\n",
      "7 ah.json\n",
      "8 ai.json\n",
      "9 aj.json\n",
      "10 ak.json\n",
      "11 al.json\n",
      "12 am.json\n",
      "13 an.json\n",
      "14 ao.json\n",
      "15 ap.json\n",
      "16 aq.json\n",
      "17 ar.json\n",
      "18 as.json\n",
      "19 at.json\n",
      "CPU times: user 1min 38s, sys: 3min 11s, total: 4min 49s\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# Function for reading all the files from the directory:\n",
    "data_one = []\n",
    "data_two = []\n",
    "data_three = []\n",
    "data_four = []\n",
    "data_five = []\n",
    "data_six = []\n",
    "data_seven = []\n",
    "data_eight =[]\n",
    "data_nine =[]\n",
    "data_ten = []\n",
    "data_eleven =[]\n",
    "data_twelve = []\n",
    "data_thirteen = []\n",
    "data_fourteen = []\n",
    "data_fifteen = []\n",
    "data_sixteen = []\n",
    "data_seventeen = []\n",
    "data_eighteen = []\n",
    "data_nineteen = []\n",
    "data_twenty = []\n",
    "\n",
    "def read_files():\n",
    "    entries = os.listdir('/Volumes/Kartikay/Data/split_dataFiles/')\n",
    "    print(entries)\n",
    "\n",
    "    print(type(entries))\n",
    "\n",
    "    for index, files in enumerate(entries):\n",
    "        print(index, files)\n",
    "        if index == 0:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_one.append(data)\n",
    "                \n",
    "        if index == 1:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_two.append(data)\n",
    "                \n",
    "        if index == 2:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_three.append(data)\n",
    "        \n",
    "        if index == 3:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_four.append(data)\n",
    "                \n",
    "        if index == 4:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_five.append(data)\n",
    "                \n",
    "        if index == 5:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_six.append(data)\n",
    "        \n",
    "        if index == 6:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_seven.append(data)\n",
    "                \n",
    "        if index == 7:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_eight.append(data)\n",
    "                \n",
    "        if index == 8:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_nine.append(data)\n",
    "                \n",
    "        if index == 9:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_ten.append(data)\n",
    "                \n",
    "        if index == 10:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_eleven.append(data)\n",
    "                \n",
    "        if index == 11:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_twelve.append(data)\n",
    "                \n",
    "        if index == 12:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_thirteen.append(data)\n",
    "                \n",
    "        if index == 13:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_fourteen.append(data)\n",
    "                \n",
    "        if index == 14:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_fifteen.append(data)\n",
    "                \n",
    "        if index == 15:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_sixteen.append(data)\n",
    "                \n",
    "        if index == 16:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_seventeen.append(data)\n",
    "                \n",
    "        if index == 17:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_eighteen.append(data)\n",
    "        \n",
    "        if index == 18:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_nineteen.append(data)\n",
    "                \n",
    "        if index == 19:\n",
    "            for lines in open(\"/Volumes/Kartikay/Data/split_dataFiles/\" + files):\n",
    "                data = json.loads(lines)\n",
    "                data_twenty.append(data)   \n",
    "                \n",
    "                \n",
    "                \n",
    "read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes from the files in the directory.\n",
    "populateData(data_one)\n",
    "frameOne = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_two)\n",
    "frameTwo = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_three)\n",
    "frameThree = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_four)\n",
    "frameFour = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_five)\n",
    "frameFive = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_six)\n",
    "frameSix = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_seven)\n",
    "frameSeven = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_eight)\n",
    "frameEight = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_nine)\n",
    "frameNine = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_ten)\n",
    "frameTen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_eleven)\n",
    "frameEleven = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_twelve)\n",
    "frameTwelve = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_thirteen)\n",
    "frameThirteen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_fourteen)\n",
    "frameFourteen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_fifteen)\n",
    "frameFifteen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_sixteen)\n",
    "frameSixteen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_seventeen)\n",
    "frameSeventeen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_eighteen)\n",
    "frameEighteen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_nineteen)\n",
    "frameNineteen = author.fileNumberGenerator()\n",
    "\n",
    "populateData(data_twenty)\n",
    "frameTwenty = author.fileNumberGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796911"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(DFV19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFV19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_dataframes = [frameTwo, frameThree, frameFour, frameFive, frameSix, frameSeven, frameEight, frameNine, frameTen, frameEleven, frameTwelve, frameThirteen, frameFourteen, frameFifteen, frameSixteen, frameSeventeen, frameEighteen, frameNineteen, frameTwenty]\n",
    "\n",
    "Final_Frame = frameOne.append(All_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796911"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Final_Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit5ab6d7df079b4313aaeebe872c08f89d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
